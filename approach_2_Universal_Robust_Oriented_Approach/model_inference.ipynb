{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DVIs2i9PaejQ","executionInfo":{"status":"ok","timestamp":1745371388962,"user_tz":-120,"elapsed":11287,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["import os\n","import joblib\n","from collections import defaultdict\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","\n","from scipy.spatial import cKDTree\n","\n","import gdown\n","import zipfile\n"]},{"cell_type":"markdown","metadata":{"id":"2pf1OYJ5aejS"},"source":["# Import Data"]},{"cell_type":"markdown","metadata":{"id":"OOBIqTwBaejS"},"source":["**Important Notes** :\n","- The code loads both the training and submission datasets because the training data is required to compute the mean and standard deviation for the standardization of features.\n","- This ensures consistent scaling is applied across both datasets."]},{"cell_type":"code","source":["file_id = \"1qtKxonXd7Cqj-GFgLozXEsz2iPKxWZL0\"\n","file_url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","output_dir = \"/content/\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","output_path = os.path.join(output_dir, \"data.zip\")\n","gdown.download(url=file_url, output=output_path, quiet=False, use_cookies=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"R7sVDuiLbjBo","executionInfo":{"status":"ok","timestamp":1745371404467,"user_tz":-120,"elapsed":15512,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}},"outputId":"8ca29635-eb0d-4728-9ccf-f0dc71ba37d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1qtKxonXd7Cqj-GFgLozXEsz2iPKxWZL0\n","From (redirected): https://drive.google.com/uc?id=1qtKxonXd7Cqj-GFgLozXEsz2iPKxWZL0&confirm=t&uuid=ebef360a-2168-4115-bcc7-fd069cbc8f28\n","To: /content/data.zip\n","100%|██████████| 2.01G/2.01G [00:11<00:00, 176MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/data.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["zip_path = os.path.join(output_dir, \"data.zip\")\n","extract_dir = os.path.join(output_dir, \"data\")\n","\n","# Create extraction directory if it doesn't exist\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","# Unzip the file\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_dir)\n","\n"],"metadata":{"id":"jeeVOaNbEMgw","executionInfo":{"status":"ok","timestamp":1745371420060,"user_tz":-120,"elapsed":15586,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dDpl9KzyaejT","executionInfo":{"status":"ok","timestamp":1745371441463,"user_tz":-120,"elapsed":21397,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["# ---------------------------\n","# Load Train Data\n","# ---------------------------\n","train_df = pd.read_csv(os.path.join('data', 'Training_data_uhi_index_2025-02-18.csv'))\n","\n","# ---------------------------\n","# Load 01_data_satellite\n","# ---------------------------\n","s1_train_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"train\", \"sentinel1_timeseries_train.pkl\"))\n","s2_train_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"train\", \"sentinel2_timeseries_train.pkl\"))\n","ls_train_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"train\", \"landsat8_timeseries_train.pkl\"))\n","\n","satellite_data = {'s1': s1_train_df, 's2': s2_train_df, 'ls': ls_train_df}\n","\n","# ---------------------------\n","# Load 02_data_weather\n","# ---------------------------\n","weather_train_dict = joblib.load(os.path.join(\"data\", \"data_processed\", \"02_data_weather\", \"weather_features_train.pkl\"))\n","\n","# ---------------------------\n","# Load 03_data_footprint\n","# ---------------------------\n","root_footprint_train_images = os.path.join(\"data\", \"data_processed\", \"03_data_footprint\", \"train\")\n","\n","# ---------------------------\n","# Load 04_data_reference_points\n","# ---------------------------\n","similarity_train_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"04_data_reference_points\", \"similarity_features_train.pkl\"))\n","\n","# ---------------------------\n","# Load 05_data_human_feature_eng\n","# ---------------------------\n","feature_engineering_train_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"05_data_human_feature_eng\", \"human_feat_eng_train.pkl\"))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fh7ZjJaqaejT","executionInfo":{"status":"ok","timestamp":1745371443336,"user_tz":-120,"elapsed":1879,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["# ---------------------------\n","# Load Submission Data\n","# ---------------------------\n","submission_template = pd.read_csv(os.path.join('data', 'Submission_template.csv'))\n","\n","# ---------------------------\n","# Load 01_data_satellite\n","# ---------------------------\n","s1_sub_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"submission\", \"sentinel1_timeseries_submission.pkl\"))\n","s2_sub_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"submission\", \"sentinel2_timeseries_submission.pkl\"))\n","ls_sub_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"01_data_satellite\", \"submission\", \"landsat8_timeseries_submission.pkl\"))\n","\n","satellite_sub_data = {'s1': s1_sub_df, 's2': s2_sub_df, 'ls': ls_sub_df}\n","# ---------------------------\n","# Load 02_data_weather\n","# ---------------------------\n","weather_sub_dict = joblib.load(os.path.join(\"data\", \"data_processed\", \"02_data_weather\", \"weather_features_sub.pkl\"))\n","\n","# ---------------------------\n","# Load 03_data_footprint\n","# ---------------------------\n","root_footprint_sub_images = os.path.join(\"data\", \"data_processed\", \"03_data_footprint\", \"submission\")\n","\n","# ---------------------------\n","# Load 04_data_reference_points\n","# ---------------------------\n","similarity_sub_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"04_data_reference_points\", \"similarity_features_submission.pkl\"))\n","\n","# ---------------------------\n","# Load 05_data_human_feature_eng\n","# ---------------------------\n","feature_engineering_sub_df = pd.read_pickle(os.path.join(\"data\", \"data_processed\", \"05_data_human_feature_eng\", \"human_feat_eng_sub.pkl\"))"]},{"cell_type":"markdown","metadata":{"id":"cZ4ANiRdaejT"},"source":["# Model Ineference"]},{"cell_type":"markdown","metadata":{"id":"mKsAiSq1aejU"},"source":["### Define Dataset Class"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"NrXyNfMraejU","executionInfo":{"status":"ok","timestamp":1745371443338,"user_tz":-120,"elapsed":11,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["# Define the dataset : UnifiedUHIDataset\n","class UnifiedUHIDataset(Dataset):\n","    def __init__(self, main_df, satellite_dfs, weather_dict, image_dir,\n","                 similarity_df, feature_engineering_df, transforms, mode='train'):\n","        \"\"\"\n","        Unified Urban Heat Island Dataset for Machine Learning.\n","\n","        Args:\n","            main_df (DataFrame/GeoDataFrame): Contains UHI targets and coordinates.\n","            satellite_dfs (dict): Dictionary with keys 's1', 's2', 'ls' containing satellite DataFrames.\n","            weather_dict (dict): Weather features dictionary keyed by (lat, lon).\n","            image_dir (str): Directory containing geographic images.\n","            similarity_df (DataFrame): DataFrame with similarity metrics between locations.\n","            feature_engineering_df (DataFrame): Feature engineered DataFrame.\n","            transforms (callable): Image transforms.\n","            mode (str): 'train' or 'submission' mode.\n","        \"\"\"\n","\n","        self.main_gdf = main_df\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","        self.mode = mode\n","\n","        print(\"Processing Satellite Data & Statistics\")\n","        self.satellite_data = self._process_satellite_data(satellite_dfs)\n","        self.satellite_stats = self._compute_satellite_stats(satellite_dfs)\n","\n","        print(\"Processing Weather Data & Statistics\")\n","        self.weather_dict = weather_dict\n","        self.feature_keys = list(next(iter(self.weather_dict.values())).keys())\n","        self.weather_stats = self._compute_weather_stats()\n","\n","        print(\"Processing Feature Engineering Data & Statistics\")\n","        self.feature_eng_data, self.feature_names = self._process_feature_engineering(feature_engineering_df)\n","        self.num_feature_eng = len(self.feature_names) if self.feature_eng_data else 0\n","        self.feature_eng_stats = self._compute_feature_eng_stats() if self.mode == 'train' else (None, None)\n","\n","        print(\"Processing Similarity Data & Statistics\")\n","        self.similarity_data, self.similarity_names = self._process_similarity_data(similarity_df)\n","        self.num_similarity = len(self.similarity_names) if self.similarity_data else 0\n","        self.similarity_stats = self._compute_similarity_stats() if self.mode == 'train' else (None, None)\n","\n","        print(\"\\nFiltering Valid Locations\")\n","        self.valid_locations = self._filter_valid_locations()\n","        if self.valid_locations:\n","            print(f\"Found {len(self.valid_locations)} valid locations\")\n","            print(\"Data Processing Completed: All Data Available\")\n","        else:\n","            print(\"Data Processing Completed: Missing Data in Sources\")\n","\n","    def _process_satellite_data(self, satellite_dfs):\n","        \"\"\"Process satellite data into location-keyed dictionaries\"\"\"\n","        processed = {}\n","        for sat_name, df in satellite_dfs.items():\n","            grouped = df.groupby(['Longitude', 'Latitude'])\n","            processed[sat_name] = {\n","                (lon, lat): group.sort_values('Period')\n","                .drop(columns=['Longitude', 'Latitude', 'Period', 'UHI Index', 'datetime'], errors='ignore')\n","                .values.astype(np.float32)\n","                for (lon, lat), group in grouped\n","            }\n","        return processed\n","\n","    def _process_feature_engineering(self, df):\n","        \"\"\"Process feature-engineered data and extract feature names.\"\"\"\n","        if df is None:\n","            return {}, []\n","\n","        feature_names = df.columns.drop(['Longitude', 'Latitude']).tolist()\n","        feature_dict = {}\n","        for _, row in df.iterrows():\n","            lon, lat = row['Longitude'], row['Latitude']\n","            features = row[feature_names].values.astype(np.float32)\n","            feature_dict[(lon, lat)] = features\n","\n","        return feature_dict, feature_names\n","\n","\n","    def _compute_satellite_stats(self, satellite_dfs):\n","        \"\"\"Compute normalization stats for each satellite feature\"\"\"\n","        stats = {}\n","        for sat_name, df in satellite_dfs.items():\n","            features = df.drop(columns=['Longitude', 'Latitude', 'Period', 'UHI Index', 'datetime'], errors='ignore')\n","            stats[sat_name] = (features.mean().values, features.std().values)\n","        return stats\n","\n","    def _compute_weather_stats(self):\n","        sum_ = defaultdict(float)\n","        sum_sq = defaultdict(float)\n","        count = defaultdict(int)\n","\n","        for idx in range(len(self.main_gdf)):\n","            lat = self.main_gdf.loc[idx, 'Latitude']\n","            lon = self.main_gdf.loc[idx, 'Longitude']\n","            weather = self.weather_dict.get((lat, lon), {})\n","\n","            for k in self.feature_keys:\n","                if k in weather:\n","                    data = weather[k].astype(np.float32)\n","                    if data.size > 0:\n","                        sum_[k] += np.nansum(data)  # Use nan-safe sum\n","                        sum_sq[k] += np.nansum(data**2)\n","                        count[k] += np.count_nonzero(~np.isnan(data))  # Only count non-NaN elements\n","\n","        mean = {k: sum_[k] / count[k] if count[k] > 0 else 0.0 for k in self.feature_keys}\n","        std = {\n","            k: np.sqrt(\n","                max(sum_sq[k] / count[k] - (sum_[k] / count[k]) ** 2, 0) + 1e-8\n","            ) if count[k] > 0 else 1.0  # Avoid division by zero and ensure non-negative variance\n","            for k in self.feature_keys\n","        }\n","\n","        return mean, std\n","\n","    def _compute_feature_eng_stats(self):\n","        \"\"\"Compute mean and std for each feature individually.\"\"\"\n","        if not self.feature_names:\n","            return ({}, {})\n","\n","        # Collect all values for each feature\n","        feature_values = {name: [] for name in self.feature_names}\n","        for loc_features in self.feature_eng_data.values():\n","            for i, name in enumerate(self.feature_names):\n","                feature_values[name].append(loc_features[i])\n","\n","        # Compute statistics\n","        mean_dict, std_dict = {}, {}\n","        for name in self.feature_names:\n","            values = np.array(feature_values[name], dtype=np.float32)\n","            mean = np.nanmean(values)\n","            std = np.nanstd(values) + 1e-8  # Avoid division by zero\n","            mean_dict[name] = mean\n","            std_dict[name] = std\n","\n","        return (mean_dict, std_dict)\n","\n","    def _process_similarity_data(self, df):\n","        \"\"\"Process similarity dataframe into location-keyed dictionary.\"\"\"\n","        if df is None:\n","            return {}, []\n","        feature_names = df.columns.drop(['Longitude', 'Latitude']).tolist()\n","        feature_dict = {}\n","        for _, row in df.iterrows():\n","            lon, lat = row['Longitude'], row['Latitude']\n","            features = row[feature_names].values.astype(np.float32)\n","            feature_dict[(lon, lat)] = features\n","        return feature_dict, feature_names\n","\n","    def _compute_similarity_stats(self):\n","        \"\"\"Compute normalization stats for similarity features.\"\"\"\n","        if not self.similarity_names:\n","            return ({}, {})\n","        feature_values = {name: [] for name in self.similarity_names}\n","        for loc_features in self.similarity_data.values():\n","            for i, name in enumerate(self.similarity_names):\n","                feature_values[name].append(loc_features[i])\n","\n","        # Compute mean and std for each feature\n","        mean_dict, std_dict = {}, {}\n","        for name in self.similarity_names:\n","            values = np.array(feature_values[name], dtype=np.float32)\n","            mean = np.nanmean(values)\n","            std = np.nanstd(values) + 1e-8\n","            mean_dict[name] = mean\n","            std_dict[name] = std\n","\n","        return mean_dict, std_dict\n","\n","\n","\n","    def _filter_valid_locations(self):\n","        \"\"\"Find locations with complete data across all sources\"\"\"\n","        valid = []\n","        for idx, row in self.main_gdf.iterrows():\n","\n","            lon, lat = row['Longitude'], row['Latitude']\n","\n","            # Check satellite data availability\n","            sat_available = all(\n","                (lon, lat) in self.satellite_data[sat_name]\n","                for sat_name in ['s1', 's2', 'ls']\n","            )\n","\n","            # Check weather data\n","            weather_available = (lat, lon) in self.weather_dict\n","\n","            # Check image file existence\n","            img_path = os.path.join( self.image_dir, f\"building_road_plot_{lon}_{lat}.png\")\n","\n","            image_available = os.path.exists(img_path)\n","\n","            feature_eng_available = (lon, lat) in self.feature_eng_data\n","\n","            similarity_available = (lon, lat) in self.similarity_data\n","\n","            if all([sat_available, weather_available, image_available,\n","                    feature_eng_available, similarity_available]):  # UPDATED\n","                valid.append(idx)\n","\n","\n","\n","        return valid\n","\n","\n","    def __len__(self):\n","        return len(self.valid_locations)\n","\n","    def __getitem__(self, idx):\n","        row = self.main_gdf.iloc[self.valid_locations[idx]]\n","        lon, lat = row['Longitude'], row['Latitude']\n","\n","        # Satellite data\n","        satellite_features = {}\n","        for sat_name in ['s1', 's2', 'ls']:\n","            data = self.satellite_data[sat_name][(lon, lat)]\n","            mean, std = self.satellite_stats[sat_name]\n","            normalized = (data - mean) / std\n","            satellite_features[sat_name] = normalized\n","\n","        # Weather data: Normalize each feature individually and stack into a 2D array\n","        weather_raw = self.weather_dict[(lat, lon)]\n","        weather_list = []\n","        mean_dict, std_dict = self.weather_stats  # these are dictionaries keyed by feature\n","        for k in self.feature_keys:\n","            # Ensure the key exists in the weather data\n","            if k in weather_raw:\n","                data = weather_raw[k].astype(np.float32)\n","                norm_data = (data - mean_dict[k]) / std_dict[k]\n","                weather_list.append(norm_data)\n","        # Stack along the feature axis (each column is one weather feature)\n","        # Assume all weather arrays have the same sequence length.\n","        weather_data = np.stack(weather_list, axis=1)\n","        weather_tensor = torch.tensor(weather_data, dtype=torch.float32)\n","\n","\n","        # Check image file existence\n","        img_path = os.path.join( self.image_dir, f\"building_road_plot_{lon}_{lat}.png\")\n","\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","\n","        # Feature-engineered data\n","        feature_eng = self.feature_eng_data[(lon, lat)]\n","        mean_dict, std_dict = self.feature_eng_stats\n","\n","        # Normalize each feature by its stats\n","        normalized_features = []\n","        for i, name in enumerate(self.feature_names):\n","            val = feature_eng[i]\n","            mean = mean_dict[name]\n","            std = std_dict[name]\n","\n","            norm_val = (val - mean) / std\n","            normalized_features.append(norm_val)\n","\n","        feature_eng_tensor = torch.tensor(normalized_features, dtype=torch.float32)\n","\n","\n","\n","\n","\n","        # Process similarity data\n","        similarity = self.similarity_data[(lon, lat)]\n","        sim_mean, sim_std = self.similarity_stats\n","\n","        normalized_similarity = [\n","            (similarity[i] - sim_mean[name]) / sim_std[name]\n","            for i, name in enumerate(self.similarity_names)\n","        ]\n","        similarity_tensor = torch.tensor(normalized_similarity, dtype=torch.float32)\n","\n","\n","\n","\n","        # Target\n","        target = torch.tensor(row['UHI Index'], dtype=torch.float32) if self.mode == 'train' else torch.tensor(-1)\n","\n","\n","        return (\n","            torch.tensor(satellite_features['s1'], dtype=torch.float32),\n","            torch.tensor(satellite_features['s2'], dtype=torch.float32),\n","            torch.tensor(satellite_features['ls'], dtype=torch.float32),\n","            weather_tensor,\n","            image,\n","            feature_eng_tensor,\n","            similarity_tensor,\n","            target,\n","            torch.tensor([lon, lat], dtype=torch.float32)\n","        )\n","\n","\n","    # Correct the collate_fn in the UnifiedUHIDataset class\n","    @staticmethod\n","    def collate_fn(batch):\n","        \"\"\"Handle variable-length sequences and ensure image size consistency\"\"\"\n","        def pad_sequences(sequences):\n","            max_len = max(seq.shape[0] for seq in sequences)\n","            padded = torch.zeros(len(sequences), max_len, sequences[0].shape[1])\n","            for i, seq in enumerate(sequences):\n","                padded[i, :seq.shape[0]] = seq\n","            return padded\n","\n","        s1_list, s2_list, ls_list, weather_list, image_list, feature_eng_list, similarity_list, target_list, loc_list = zip(*batch)\n","\n","        return {  # Fixed 'ls' key to use ls_list and corrected syntax\n","            's1': pad_sequences(s1_list),\n","            's2': pad_sequences(s2_list),\n","            'ls': pad_sequences(ls_list),  # Corrected from s2_list to ls_list\n","            'weather': pad_sequences(weather_list),\n","            'image': torch.stack(image_list),\n","            'feature_eng': torch.stack(feature_eng_list),\n","            'similarity': torch.stack(similarity_list),\n","            'target': torch.stack(target_list),\n","            'location': torch.stack(loc_list)\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"4GNdHY7baejV"},"source":["### Define Model Clas"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8eQUr9KSaejV","executionInfo":{"status":"ok","timestamp":1745371443358,"user_tz":-120,"elapsed":3,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["# 1. Enhanced GRU/LSTM with attention mechanism\n","class TemporalAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size),\n","            nn.Tanh(),\n","            nn.Linear(hidden_size, 1)\n","        )\n","\n","    def forward(self, outputs):\n","        attn_weights = F.softmax(self.attention(outputs).squeeze(-1), dim=1)\n","        return (outputs * attn_weights.unsqueeze(-1)).sum(1)\n","\n","class EnhancedGRU(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n","        super().__init__()\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers,\n","                          dropout=0.3, batch_first=True, bidirectional=True)\n","        self.attention = TemporalAttention(hidden_size * 2)\n","        self.norm = nn.LayerNorm(hidden_size * 2)\n","        self.fc = nn.Linear(hidden_size * 2, output_size)\n","\n","    def forward(self, x):\n","        outputs, _ = self.gru(x)\n","        attended = self.attention(outputs)\n","        return self.fc(self.norm(attended))\n","\n","# 2. Enhanced CNN with more regularization\n","class ResidualBlock(nn.Module):\n","    \"\"\"Basic residual block for image processing\"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, 1, stride),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        return F.relu(out)\n","\n","class DeepCNN(nn.Module):\n","    def __init__(self, output_size):\n","        super().__init__()\n","        self.base = nn.Sequential(\n","            nn.Conv2d(3, 64, 7, stride=2, padding=3),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.Dropout2d(0.1),\n","            nn.MaxPool2d(3, stride=2, padding=1)\n","        )\n","        self.res_blocks = nn.Sequential(\n","            ResidualBlock(64, 128, stride=2),\n","            ResidualBlock(128, 256, stride=2),\n","        )\n","        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.dropout = nn.Dropout(0.3)\n","        self.fc = nn.Linear(256, output_size)\n","\n","    def forward(self, x):\n","        x = self.base(x)\n","        x = self.res_blocks(x)\n","        x = self.adaptive_pool(x)\n","        x = self.dropout(x.view(x.size(0), -1))\n","        return self.fc(x)\n","\n","\n","# 3. Enhanced feature extractors with skip connections\n","class FeatureEngExtractor(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Linear(input_size, 128),\n","            nn.LayerNorm(128),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(128, output_size),\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","# 4. Improved fusion network\n","class FusionNetwork(nn.Module):\n","    def __init__(self, input_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, 64),\n","            nn.LayerNorm(64),\n","            nn.LeakyReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(64, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x).squeeze()\n","\n","# Unified predictor remains unchanged (automatically handles concatenated features)\n","class UnifiedUHIPredictor(nn.Module):\n","    def __init__(self,\n","                 s1_input=8, s2_input=52, ls_input=12, weather_input=31,\n","                 s1_hidden=16, s2_hidden=32, ls_hidden=24, weather_hidden=32,\n","                 num_feature_eng=12, num_similarity=3,\n","                 image_output=64, feature_eng_output=64, similarity_output=32,\n","\n","                ):\n","        super().__init__()\n","\n","\n","        s1_output = s1_hidden * 2\n","        s2_output = s2_hidden * 2\n","        ls_output = ls_hidden * 2\n","        weather_output = weather_hidden * 2\n","\n","        # Bidirectional feature extractors\n","        self.s1_gru = EnhancedGRU(s1_input, s1_hidden, s1_output)\n","        self.s2_gru = EnhancedGRU(s2_input, s2_hidden, s2_output, num_layers=3)\n","        self.ls_gru = EnhancedGRU(ls_input, ls_hidden, ls_output)\n","        self.weather_lstm = EnhancedGRU(weather_input, weather_hidden, weather_output, num_layers=3)\n","        self.image_cnn = DeepCNN(output_size=image_output)\n","\n","        # Add feature-engineered processor\n","        self.feature_eng_extractor = FeatureEngExtractor(input_size=num_feature_eng,output_size=feature_eng_output)\n","\n","        # Add similarity processor\n","        self.similarity_extractor = FeatureEngExtractor(input_size=num_similarity,output_size=similarity_output)\n","\n","\n","\n","\n","        # Fusion input now includes bidirectional outputs automatically\n","        fusion_input_dim = s1_output + s2_output + ls_output + weather_output + image_output + feature_eng_output + similarity_output\n","\n","        self.fusion = FusionNetwork(fusion_input_dim)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            nn.init.kaiming_normal_(module.weight)\n","            if module.bias is not None:\n","                nn.init.constant_(module.bias, 0.1)\n","        elif isinstance(module, nn.GRU) or isinstance(module, nn.LSTM):\n","            for name, param in module.named_parameters():\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_normal_(param.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(param.data)\n","                elif 'bias' in name:\n","                    nn.init.constant_(param.data, 0)\n","\n","\n","    def forward(self, batch):\n","        s1_emb = self.s1_gru(batch['s1'])\n","        s2_emb = self.s2_gru(batch['s2'])\n","        ls_emb = self.ls_gru(batch['ls'])\n","        w_emb = self.weather_lstm(batch['weather'])\n","        img_emb = self.image_cnn(batch['image'])\n","        feature_eng_emb = self.feature_eng_extractor(batch['feature_eng'])\n","        similarity_emb = self.similarity_extractor(batch['similarity'])\n","\n","        # Concatenate all features\n","        combined = torch.cat([s1_emb, s2_emb, ls_emb, w_emb, img_emb, feature_eng_emb, similarity_emb], dim=1)\n","\n","        return self.fusion(combined).squeeze()\n"]},{"cell_type":"markdown","metadata":{"id":"NwBHmRlZaejW"},"source":["### Inference on Submission"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGl8YZ7daejW","executionInfo":{"status":"ok","timestamp":1745371499227,"user_tz":-120,"elapsed":55870,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}},"outputId":"f4a07cab-7165-44d9-c5c5-582a9725e6fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Satellite Data & Statistics\n","Processing Weather Data & Statistics\n","Processing Feature Engineering Data & Statistics\n","Processing Similarity Data & Statistics\n","\n","Filtering Valid Locations\n","Found 11229 valid locations\n","Data Processing Completed: All Data Available\n"]}],"source":["# Create the train dataset to exract the statistics for normalization\n","\n","# Transforms for images\n","image_transforms = transforms.Compose([\n","    transforms.Resize(256),          # Resize shorter side to 256\n","    transforms.CenterCrop(256),      # Ensure square 256x256 images\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","# Initialize dataset and loaders\n","training_dataset = UnifiedUHIDataset(\n","    train_df, satellite_data, weather_train_dict,\n","    root_footprint_train_images,\n","    similarity_train_df,\n","    feature_engineering_train_df,\n","    transforms=image_transforms\n","    )\n","\n","satellite_stats = training_dataset.satellite_stats\n","weather_stats = training_dataset.weather_stats\n","feature_eng_stats = training_dataset.feature_eng_stats\n","similarity_stats = training_dataset.similarity_stats"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emM48jxYaejX","executionInfo":{"status":"ok","timestamp":1745371503816,"user_tz":-120,"elapsed":4587,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}},"outputId":"bee64fbc-8227-4d0f-f3a5-16c6853a4968"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Satellite Data & Statistics\n","Processing Weather Data & Statistics\n","Processing Feature Engineering Data & Statistics\n","Processing Similarity Data & Statistics\n","\n","Filtering Valid Locations\n","Found 1040 valid locations\n","Data Processing Completed: All Data Available\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["# Create the submission dataset\n","submission_dataset = UnifiedUHIDataset(\n","    submission_template, satellite_sub_data, weather_sub_dict,\n","    root_footprint_sub_images,\n","    similarity_sub_df,\n","    feature_engineering_sub_df,\n","    transforms=image_transforms,\n","    mode='submission'\n","    )\n","\n","\n","submission_dataset.satellite_stats = satellite_stats\n","submission_dataset.weather_stats = weather_stats\n","submission_dataset.feature_eng_stats = feature_eng_stats\n","submission_dataset.similarity_stats = similarity_stats\n","\n","num_feature_eng = training_dataset.num_feature_eng\n","num_similarity = training_dataset.num_similarity\n","\n","# Create DataLoader\n","submission_loader = DataLoader(\n","    submission_dataset,\n","    batch_size=128,\n","    shuffle=False,\n","    collate_fn=submission_dataset.collate_fn,\n","    num_workers=8\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLz8HwqlaejY","executionInfo":{"status":"ok","timestamp":1745371504407,"user_tz":-120,"elapsed":537,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}},"outputId":"1ae1389f-446f-4b83-c52a-f2717457cb64"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["UnifiedUHIPredictor(\n","  (s1_gru): EnhancedGRU(\n","    (gru): GRU(8, 16, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n","    (attention): TemporalAttention(\n","      (attention): Sequential(\n","        (0): Linear(in_features=32, out_features=32, bias=True)\n","        (1): Tanh()\n","        (2): Linear(in_features=32, out_features=1, bias=True)\n","      )\n","    )\n","    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","    (fc): Linear(in_features=32, out_features=32, bias=True)\n","  )\n","  (s2_gru): EnhancedGRU(\n","    (gru): GRU(52, 32, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n","    (attention): TemporalAttention(\n","      (attention): Sequential(\n","        (0): Linear(in_features=64, out_features=64, bias=True)\n","        (1): Tanh()\n","        (2): Linear(in_features=64, out_features=1, bias=True)\n","      )\n","    )\n","    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (fc): Linear(in_features=64, out_features=64, bias=True)\n","  )\n","  (ls_gru): EnhancedGRU(\n","    (gru): GRU(12, 24, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n","    (attention): TemporalAttention(\n","      (attention): Sequential(\n","        (0): Linear(in_features=48, out_features=48, bias=True)\n","        (1): Tanh()\n","        (2): Linear(in_features=48, out_features=1, bias=True)\n","      )\n","    )\n","    (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n","    (fc): Linear(in_features=48, out_features=48, bias=True)\n","  )\n","  (weather_lstm): EnhancedGRU(\n","    (gru): GRU(31, 32, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n","    (attention): TemporalAttention(\n","      (attention): Sequential(\n","        (0): Linear(in_features=64, out_features=64, bias=True)\n","        (1): Tanh()\n","        (2): Linear(in_features=64, out_features=1, bias=True)\n","      )\n","    )\n","    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (fc): Linear(in_features=64, out_features=64, bias=True)\n","  )\n","  (image_cnn): DeepCNN(\n","    (base): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout2d(p=0.1, inplace=False)\n","      (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (res_blocks): Sequential(\n","      (0): ResidualBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): ResidualBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (adaptive_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (fc): Linear(in_features=256, out_features=64, bias=True)\n","  )\n","  (feature_eng_extractor): FeatureEngExtractor(\n","    (block): Sequential(\n","      (0): Linear(in_features=200, out_features=128, bias=True)\n","      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Dropout(p=0.2, inplace=False)\n","      (4): Linear(in_features=128, out_features=64, bias=True)\n","    )\n","  )\n","  (similarity_extractor): FeatureEngExtractor(\n","    (block): Sequential(\n","      (0): Linear(in_features=441, out_features=128, bias=True)\n","      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Dropout(p=0.2, inplace=False)\n","      (4): Linear(in_features=128, out_features=32, bias=True)\n","    )\n","  )\n","  (fusion): FusionNetwork(\n","    (net): Sequential(\n","      (0): Linear(in_features=368, out_features=64, bias=True)\n","      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Dropout(p=0.2, inplace=False)\n","      (4): Linear(in_features=64, out_features=1, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":10}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","model = UnifiedUHIPredictor(\n","    num_feature_eng=num_feature_eng, num_similarity=num_similarity\n","    ).to(device)\n","\n","best_model_path = os.path.join('data', 'best_model.pth')\n","model.load_state_dict(torch.load(best_model_path))\n","model.eval()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K2Du4VfbaejY","executionInfo":{"status":"ok","timestamp":1745371514976,"user_tz":-120,"elapsed":10566,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}}},"outputs":[],"source":["predictions = []\n","locations = []\n","\n","with torch.no_grad():\n","    for _batch in submission_loader:\n","        inputs = {k: v.to(device) for k, v in _batch.items() if k != 'target'}\n","        batch_locs = _batch['location'].cpu().numpy()\n","        outputs = model(inputs).cpu().numpy().flatten()\n","        predictions.extend(outputs.tolist())\n","        locations.extend(batch_locs.tolist())\n","\n","# Convert to DataFrame\n","results_df = pd.DataFrame(locations, columns=['Longitude', 'Latitude'])\n","results_df['UHI_Predicted'] = predictions\n","results_df = results_df.groupby(['Longitude', 'Latitude']).last().reset_index()\n","# Build a k-D tree from the results_df coordinates for fast nearest neighbor search.\n","tree = cKDTree(results_df[['Longitude', 'Latitude']].values)\n","\n","# Query the tree for the nearest neighbor for each point in the submission template.\n","# dists: Euclidean distances (not used here, but can be useful for quality checks)\n","# indices: indices of the nearest neighbors in results_df\n","dists, indices = tree.query(submission_template[['Longitude', 'Latitude']].values, k=1)\n","\n","# Use the indices to assign the corresponding predicted UHI values to the submission template.\n","submission_template['UHI Index'] = results_df.iloc[indices]['UHI_Predicted'].values"]},{"cell_type":"code","source":["# Export the final submission as a CSV file.\n","output_dir = 'data'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","save_submission_path = os.path.join(output_dir, 'submission.csv')\n","submission_template.to_csv(save_submission_path, index=False)\n","\n","# Optional: Display the final DataFrame to verify the matching.\n","print(submission_template)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqg-0Z8NGlVF","executionInfo":{"status":"ok","timestamp":1745371514980,"user_tz":-120,"elapsed":8,"user":{"displayName":"Achraf Drissi","userId":"00039111242320783449"}},"outputId":"8803c55d-168c-4101-8e78-be71ec9902f2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["      Longitude   Latitude  UHI Index\n","0    -73.971665  40.788763   0.959750\n","1    -73.971928  40.788875   0.960044\n","2    -73.967080  40.789080   0.960680\n","3    -73.972550  40.789082   0.960373\n","4    -73.969697  40.787953   0.958746\n","...         ...        ...        ...\n","1035 -73.919388  40.813803   1.042457\n","1036 -73.931033  40.833178   1.043393\n","1037 -73.934647  40.854542   1.040872\n","1038 -73.917223  40.815413   1.037010\n","1039 -73.911645  40.804402   1.036858\n","\n","[1040 rows x 3 columns]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[],"collapsed_sections":["mKsAiSq1aejU","4GNdHY7baejV"],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}